{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-04T13:32:36.974806Z",
     "iopub.status.busy": "2024-04-04T13:32:36.974429Z",
     "iopub.status.idle": "2024-04-04T13:32:46.383978Z",
     "shell.execute_reply": "2024-04-04T13:32:46.383071Z",
     "shell.execute_reply.started": "2024-04-04T13:32:36.974766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle # for shuffling\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CLASS_NAMES = [\"Amphibia\", \"Animalia\", \"Arachnida\", \"Aves\", \n",
    "               \"Fungi\", \"Insecta\", \"Mammalia\", \"Mollusca\", \n",
    "               \"Plantae\", \"Reptilia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb\n",
    "import wandb\n",
    "# !wandb login\n",
    "wandb.login(key=\"ad59fd6ee8f94be6bca41cbc7385976e9111be2b\")\n",
    "\n",
    "#ad59fd6ee8f94be6bca41cbc7385976e9111be2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T13:32:49.470882Z",
     "iopub.status.busy": "2024-04-04T13:32:49.470421Z",
     "iopub.status.idle": "2024-04-04T13:32:49.475967Z",
     "shell.execute_reply": "2024-04-04T13:32:49.474307Z",
     "shell.execute_reply.started": "2024-04-04T13:32:49.470853Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip -O nature_12K.zip\n",
    "!unzip -q nature_12K.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T13:33:33.348880Z",
     "iopub.status.busy": "2024-04-04T13:33:33.347923Z",
     "iopub.status.idle": "2024-04-04T13:33:34.919254Z",
     "shell.execute_reply": "2024-04-04T13:33:34.917973Z",
     "shell.execute_reply.started": "2024-04-04T13:33:33.348839Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm nature_12K.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T13:33:34.921153Z",
     "iopub.status.busy": "2024-04-04T13:33:34.920840Z",
     "iopub.status.idle": "2024-04-04T13:33:35.032375Z",
     "shell.execute_reply": "2024-04-04T13:33:35.031201Z",
     "shell.execute_reply.started": "2024-04-04T13:33:34.921128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T13:33:36.579157Z",
     "iopub.status.busy": "2024-04-04T13:33:36.578769Z",
     "iopub.status.idle": "2024-04-04T13:33:36.699690Z",
     "shell.execute_reply": "2024-04-04T13:33:36.698477Z",
     "shell.execute_reply.started": "2024-04-04T13:33:36.579123Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "resize_width = 224\n",
    "resize_height= 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T13:33:36.701368Z",
     "iopub.status.busy": "2024-04-04T13:33:36.701060Z",
     "iopub.status.idle": "2024-04-04T13:33:36.713686Z",
     "shell.execute_reply": "2024-04-04T13:33:36.712582Z",
     "shell.execute_reply.started": "2024-04-04T13:33:36.701343Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 2: data transforms and dataloader factory\n",
    "def make_transforms(img_size: int, augment: bool):\n",
    "    base = [\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,)*3, (0.5,)*3),\n",
    "    ]\n",
    "    if augment:\n",
    "        aug = [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.RandomResizedCrop(img_size),\n",
    "        ]\n",
    "        return transforms.Compose(base[:2] + aug + base[2:])\n",
    "    return transforms.Compose(base)\n",
    "\n",
    "def get_dataloaders(data_dir: str, batch_size: int, img_size: int, augment: bool):\n",
    "    train_dir = os.path.join(data_dir, \"train\")\n",
    "    val_dir   = os.path.join(data_dir, \"val\")\n",
    "\n",
    "    train_ds = datasets.ImageFolder(train_dir, make_transforms(img_size, augment))\n",
    "    val_ds   = datasets.ImageFolder(val_dir,   make_transforms(img_size, False))\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T13:33:36.717115Z",
     "iopub.status.busy": "2024-04-04T13:33:36.716594Z",
     "iopub.status.idle": "2024-04-04T13:33:36.729139Z",
     "shell.execute_reply": "2024-04-04T13:33:36.727950Z",
     "shell.execute_reply.started": "2024-04-04T13:33:36.717090Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 3: SimpleCNN definition\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, in_channels, conv_specs, dense_units, num_classes, dropout, use_bn):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        C = in_channels\n",
    "        for out_c, k in conv_specs:\n",
    "            layers += [\n",
    "                nn.Conv2d(C, out_c, kernel_size=k),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "            ]\n",
    "            if use_bn:\n",
    "                layers.append(nn.BatchNorm2d(out_c))\n",
    "            C = out_c\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "        # infer flattened feature size\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, in_channels, img_size, img_size)\n",
    "            feat_dim = self.conv(dummy).view(1, -1).shape[1]\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(feat_dim, dense_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dense_units, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.conv(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: train/validate functions\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, count = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            logits = model(X)\n",
    "            total_loss += criterion(logits, y).item()\n",
    "            preds = logits.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            count += y.size(0)\n",
    "    return total_loss/len(loader), 100 * correct/count\n",
    "\n",
    "def train_loop(model, train_loader, val_loader, epochs, lr, wd):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\")\n",
    "        for X, y in loop:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(X), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss, train_acc = evaluate(model, train_loader, criterion)\n",
    "        val_loss,   val_acc   = evaluate(model, val_loader,   criterion)\n",
    "        print(f\"Train: {train_loss:.4f}, {train_acc:.1f}% | Val: {val_loss:.4f}, {val_acc:.1f}%\")\n",
    "\n",
    "        # wandb.log({\n",
    "        #     \"train_loss\": train_loss, \"train_acc\": train_acc,\n",
    "        #     \"val_loss\": val_loss,     \"val_acc\": val_acc\n",
    "        # })\n",
    "\n",
    "        # wandb.log({f'{dataName}_accuracy': 100*correct/total})\n",
    "        # wandb.log({f'{dataName}_loss': val_loss/len(dataLoader)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: hyperparams, wandb, and launch\n",
    "img_size   = 128\n",
    "batch_size = 32\n",
    "epochs     = 10\n",
    "lr, wd      = 1e-3, 1e-4\n",
    "augment     = True\n",
    "\n",
    "wandb.init(project=\"Deep_Learning_Assignment_2\", entity=\"cs24m023-indian-institute-of-technology-madras\",\n",
    "           config={\"img_size\":img_size, \"batch\":batch_size, \n",
    "                   \"epochs\":epochs, \"lr\":lr, \"wd\":wd, \"aug\":augment})\n",
    "\n",
    "model = SimpleCNN(\n",
    "    in_channels=3,\n",
    "    conv_specs=[(32,3),(32,3),(64,3)],\n",
    "    dense_units=128,\n",
    "    num_classes=len(CLASS_NAMES),\n",
    "    dropout=0.2,\n",
    "    use_bn=True\n",
    ").to(DEVICE)\n",
    "\n",
    "train_loader, val_loader = get_dataloaders(\"nature_12K\", batch_size, img_size, augment)\n",
    "train_loop(model, train_loader, val_loader, epochs, lr, wd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(learning_rate = 0.0001, num_filters = [128,128,64,64,32], filter_sizes=[3,5,3,5,3], \n",
    "                    activation_fn = \"elu\", optimiser_fn =\"rmsprop\", num_neurons_dense = 512, \n",
    "                    weight_decay = 0.0004, dropout = 0.4, useBatchNorm = True, batchSize = 32, \n",
    "                    num_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataLoader, valDataLoader, testDataLoader = load_data(train_dir = 'inaturalist_12K/train', test_dir = 'inaturalist_12K/val', batchSize = 16)\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "find_accuracy(model, criterion, valDataLoader, \"val\")\n",
    "find_accuracy(model, criterion, testDataLoader, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "# Initialize Weights & Biases tracking\n",
    "wandb_session = wandb.init(\n",
    "    project=\"Deep_Learning_Assignment_2\",\n",
    "    config={\"architecture\": \"ResNet50\", \"dataset\": \"iNaturalist10\"}\n",
    ")\n",
    "\n",
    "# Set model to evaluation mode and detect device\n",
    "model_device = next(model.parameters()).device\n",
    "model.eval()\n",
    "\n",
    "# Configure sample collection parameters\n",
    "num_classes = 10\n",
    "max_examples = 3\n",
    "class_examples = {cls_id: [] for cls_id in range(num_classes)}\n",
    "\n",
    "# Collect model predictions on validation set\n",
    "with torch.no_grad():\n",
    "    for batch_images, batch_labels in valDataLoader:\n",
    "        batch_images = batch_images.to(model_device)\n",
    "        batch_labels = batch_labels.to(model_device)\n",
    "        \n",
    "        # Check if all classes have sufficient samples\n",
    "        collection_complete = all(len(examples) >= max_examples \n",
    "                                for examples in class_examples.values())\n",
    "        if collection_complete:\n",
    "            break\n",
    "            \n",
    "        for single_image, true_label in zip(batch_images, batch_labels):\n",
    "            class_id = true_label.item()\n",
    "            if len(class_examples[class_id]) < max_examples:\n",
    "                # Get model prediction\n",
    "                prediction = model(single_image.unsqueeze(0)).argmax(dim=1).item()\n",
    "                # Store image and prediction (move to CPU for plotting)\n",
    "                class_examples[class_id].append((\n",
    "                    single_image.cpu().clone(),\n",
    "                    prediction\n",
    "                ))\n",
    "\n",
    "# Image normalization reversal function\n",
    "def restore_original_image(normalized_img):\n",
    "    normalization_mean = torch.tensor([0.485, 0.456, 0.406]).reshape(3, 1, 1)\n",
    "    normalization_std = torch.tensor([0.229, 0.224, 0.225]).reshape(3, 1, 1)\n",
    "    return normalized_img * normalization_std + normalization_mean\n",
    "\n",
    "# Create visualization grid\n",
    "figure, axis_grid = plt.subplots(num_classes, max_examples, figsize=(15, 35))\n",
    "for class_idx in range(num_classes):\n",
    "    for example_idx in range(max_examples):\n",
    "        img_tensor, pred_class = class_examples[class_idx][example_idx]\n",
    "        original_image = restore_original_image(img_tensor)\n",
    "        \n",
    "        current_axis = axis_grid[class_idx, example_idx]\n",
    "        current_axis.imshow(original_image.permute(1, 2, 0).numpy())\n",
    "        current_axis.set_title(\n",
    "            f\"Actual: {classesList[class_idx]}\\nPredicted: {classesList[pred_class]}\",\n",
    "            fontsize=9\n",
    "        )\n",
    "        current_axis.axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.6)\n",
    "visualization_path = \"/kaggle/working/class_predictions_grid.png\"\n",
    "plt.savefig(visualization_path, bbox_inches='tight', pad_inches=0.2, dpi=250)\n",
    "plt.close()\n",
    "\n",
    "# Log results to W&B\n",
    "wandb.log({\"validation_predictions\": wandb.Image(visualization_path)})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-04T09:48:56.555696Z",
     "iopub.status.idle": "2024-04-04T09:48:56.556077Z",
     "shell.execute_reply": "2024-04-04T09:48:56.555893Z",
     "shell.execute_reply.started": "2024-04-04T09:48:56.555878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    wandb.init(project=\"Deep_Learning_Assignment_2\")\n",
    "    config = wandb.config\n",
    "    run_name = f\"{config.optimiser}_{config.activation}_{config.num_filters}_{config.batch_size}\"\n",
    "\n",
    "    # Set the run name\n",
    "    wandb.run.name = run_name\n",
    "    wandb.run.save()\n",
    "\n",
    "    # Define and train the model as before\n",
    "    train_model(learning_rate = config.learning_rate, num_filters = config.num_filters,\n",
    "                filter_sizes = config.filter_sizes, activation_fn = config.activation, \n",
    "                optimiser_fn = config.optimiser, num_neurons_dense = config.dense_layer,\n",
    "                weight_decay = config.weight_decay, dropout = config.dropout, useBatchNorm = False, \n",
    "                batchSize = config.batch_size, num_epochs = 10)\n",
    "    \n",
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'name' : 'sweep cross entropy',\n",
    "    'metric': {\n",
    "      'name': 'validation_accuracy',\n",
    "      'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'num_filters': {\n",
    "          'values': [[32,32,32,32,32],[32,64,64,128,128],[128,128,64,64,32],[32,64,128,256,512]]\n",
    "        },\n",
    "        'filter_sizes': {\n",
    "          'values': [[3,3,3,3,3], [5,5,5,5,5], [3,5,3,5,3]]\n",
    "        },\n",
    "        'weight_decay': {\n",
    "            'values':[0, 0.0005, 0.5]\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'values':[1e-3,1e-4]\n",
    "        },\n",
    "        'weight_decay': {\n",
    "            'values': [0, 0.0005, 0.005]\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0, 0.2, 0.4]\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'values': [1e-3, 1e-4]\n",
    "        },\n",
    "        'activation': {\n",
    "            'values': ['relu', 'elu', 'selu']\n",
    "        },\n",
    "        'optimiser': {\n",
    "            'values': ['nadam', 'adam', 'rmsprop']\n",
    "        },\n",
    "        'batch_norm':{\n",
    "            'values': ['true','false']\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [32, 64]\n",
    "        },\n",
    "        'dense_layer':{\n",
    "            'values': [128, 256, 512]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_config,project='Deep_Learning_Assignment_2')\n",
    "wandb.agent(\"hpi0co5y\" , function = main , count = 50)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
